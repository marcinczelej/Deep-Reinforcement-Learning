{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import a3cNetwork\n",
    "import numpy as np\n",
    "from sharedOptimizer import sharedAdam\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from test import test\n",
    "from train import train\n",
    "import vizdoom\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class params:\n",
    "    seed = 4\n",
    "    env_name = \"CartPole-v0\"\n",
    "    state_space = 4\n",
    "    action_space = 2\n",
    "    n_steps = 10\n",
    "    gamma = 0.99\n",
    "    tau = 0.5\n",
    "    lr = 0.001\n",
    "    number_of_processes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  reward =  26.0 , | means score =  27.4  | max reward =  61.0\n",
      "20  reward =  117.0 , | means score =  60.45  | max reward =  200.0\n",
      "30  reward =  200.0 , | means score =  84.4  | max reward =  200.0\n",
      "40  reward =  200.0 , | means score =  107.525  | max reward =  200.0\n",
      "50  reward =  200.0 , | means score =  118.7  | max reward =  200.0\n",
      "60  reward =  200.0 , | means score =  127.25  | max reward =  200.0\n",
      "70  reward =  200.0 , | means score =  137.64285714285714  | max reward =  200.0\n",
      "80  reward =  200.0 , | means score =  143.2375  | max reward =  200.0\n",
      "90  reward =  200.0 , | means score =  148.53333333333333  | max reward =  200.0\n",
      "100  reward =  200.0 , | means score =  152.88  | max reward =  200.0\n",
      "110  reward =  200.0 , | means score =  169.26  | max reward =  200.0\n",
      "120  reward =  200.0 , | means score =  179.91  | max reward =  200.0\n",
      "130  reward =  200.0 , | means score =  186.68  | max reward =  200.0\n",
      "140  reward =  200.0 , | means score =  188.99  | max reward =  200.0\n",
      "150  reward =  200.0 , | means score =  192.65  | max reward =  200.0\n",
      "AI won in episode  158  with mean score of :  195.65\n"
     ]
    }
   ],
   "source": [
    "shared_model = a3cNetwork(params.state_space, params.action_space, device)\n",
    "shared_model.share_memory()\n",
    "\n",
    "shared_optimizer = sharedAdam(shared_model.parameters(), lr = params.lr)\n",
    "\n",
    "processes = []\n",
    "p = mp.Process(target = test, args = (params, shared_model, device))\n",
    "p.start()\n",
    "processes.append(p)\n",
    "\n",
    "for i in range(params.number_of_processes):\n",
    "    p = mp.Process(target = train, args = (i, params, shared_model, shared_optimizer, device))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for i in range(len(processes)):\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep_reinforcement)",
   "language": "python",
   "name": "deep_reinforcement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
